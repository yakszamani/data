from transformers import pipeline

# Load the fine-tuned model
fine_tuned_model = AutoModelForCausalLM.from_pretrained('./fine-tuned-llama-sales')
fine_tuned_tokenizer = AutoTokenizer.from_pretrained('./fine-tuned-llama-sales')

# Create a text generation pipeline
qa_pipeline = pipeline('text-generation', model=fine_tuned_model, tokenizer=fine_tuned_tokenizer)

# Generate an answer for a new question
new_question = "What is the best strategy to increase sales?"
answer = qa_pipeline(new_question, max_length=512)
print(answer)
