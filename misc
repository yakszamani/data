from transformers import pipeline

# Load the fine-tuned model
fine_tuned_model = AutoModelForCausalLM.from_pretrained('./fine-tuned-kassie')
fine_tuned_tokenizer = AutoTokenizer.from_pretrained('./fine-tuned-kassie')

# Create a text generation pipeline
qa_pipeline = pipeline('text-generation', model=fine_tuned_model, tokenizer=fine_tuned_tokenizer)

# Generate an answer for a new question
new_question = "What is the best strategy to increase sales?"
answer = qa_pipeline(new_question, max_length=512)
print(answer)


save_path = "/home/yaki/ml/projects/kassie/fine-tuned-kassie"

https://walmart.zoom.us/j/96023551756?pwd=ZAlchCaWNhbVPCRPHWbfBq5Cfikxhe.1&from=addon
